{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGR Stock Price Forecasting Project\n",
    "\n",
    "Author: Jack Wang\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Stock prices are hard to predict because they are not only affected by the performance of the underlying companies but also the expectations from the general public. As known, the stock price of firearm companies are highly correlated to the public opinions toward gun ban. My model intends to predict the stock price of one of the largest firearm company in the states, RGR (Sturm, Ruger & Co., firearm company), by using its historical stock price and public opinions toward gun ban. \n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "The goal of my projcet is to build a **time series regression model** that predicts the stock price of RGR. The data I am using would be historical stock price from Yahoo Finance, twitter posts scraped from [twitter](https://twitter.com/), and also the news articles from major news website. I will perform NPL on the text data and time series modeling on the historical stock price data. The model will be evaluated using R^2 score.\n",
    "\n",
    "## Content\n",
    "\n",
    "This project consists of 5 Jupyter notebooks:\n",
    "- Part-1-stock-price-data\n",
    "- Part-2-twitter-scraper\n",
    "- Part-3-twitter-data-cleaning\n",
    "- Part-4-reddit-data-scraper\n",
    "- ***Part-5-reddit-data-cleaning***\n",
    "- Part-4-combined-data-and-EDA\n",
    "- Part-5-modeling\n",
    "    - [Example](#Most-Frequent-Words-in-Title-and-Content)\n",
    "- Part-6-Conclusion-and-Discussion\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import itertools\n",
    "# import re\n",
    "\n",
    "from datetime import datetime\n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/SEC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Filing Date']= pd.to_datetime(df['Filing Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']= pd.to_datetime(df['Filing Date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-K         44\n",
       "SC 13G/A    14\n",
       "10-Q        11\n",
       "UPLOAD       6\n",
       "PX14A6G      5\n",
       "CORRESP      4\n",
       "DEF 14A      3\n",
       "DEFA14A      3\n",
       "10-K         3\n",
       "SD           3\n",
       "SC 13G       2\n",
       "S-8 POS      1\n",
       "S-8          1\n",
       "Name: Filings, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Filings'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[(df['Filings']=='8-K')|(df['Filings']=='10-K')|(df['Filings']=='10-Q'),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df,columns=['Filings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[5:54].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='Filing Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['date', '10-k', '10-q', '8-k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('date').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/sec_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
