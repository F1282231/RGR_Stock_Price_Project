{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGR Stock Price Forecasting Project\n",
    "\n",
    "Author: Jack Wang\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Stock prices are hard to predict because they are not only affected by the performance of the underlying companies but also the expectations from the general public. As known, the stock price of firearm companies are highly correlated to the public opinions toward gun ban. My model intends to predict the stock price of one of the largest firearm company in the states, RGR (Sturm, Ruger & Co., firearm company), by using its historical stock price and public opinions toward gun ban. \n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "The goal of my projcet is to build a **time series regression model** that predicts the stock price of RGR. The data I am using would be historical stock price from Yahoo Finance, twitter posts scraped from [twitter](https://twitter.com/), and also the news articles from major news website. I will perform NPL on the text data and time series modeling on the historical stock price data. The model will be evaluated using R^2 score.\n",
    "\n",
    "## Content\n",
    "\n",
    "This project consists of 5 Jupyter notebooks:\n",
    "- Part-1-stock-price-data\n",
    "- Part-2-twitter-scraper\n",
    "- Part-3-twitter-data-cleaning\n",
    "- ***Part-4-reddit-data-scraper***\n",
    "- Part-5-reddit-data-cleaning\n",
    "- Part-6-combined-data-and-EDA\n",
    "- Part-5-modeling\n",
    "    - [Example](#Most-Frequent-Words-in-Title-and-Content)\n",
    "- Part-6-Conclusion-and-Discussion\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Reddit API does not allow us to scrape historical data by dates, I requested the historical data from `pushshift`. This API has the historical data from Reddit. Most of the codes below are referenced from [here](https://medium.com/@RareLoot/using-pushshifts-api-to-extract-reddit-submissions-fb517b286563)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to specify subreddit, keywords, time range\n",
    "\n",
    "def getPushshiftData(query, after, before, sub):\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission/?title='+str(query)+'&size=1000&after='+str(after)+'&before='+str(before)+'&subreddit='+str(sub)\n",
    "    print(url)\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    return data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to request data including subreddit post score, author id, title, time, etc...\n",
    "\n",
    "def collectSubData(subm):\n",
    "    subData = list() # list to store data points\n",
    "    title = subm['title']\n",
    "    url = subm['url']\n",
    "    try:\n",
    "        flair = subm['link_flair_text']\n",
    "    except KeyError:\n",
    "        flair = \"NaN\"    \n",
    "    author = subm['author']\n",
    "    sub_id = subm['id']\n",
    "    score = subm['score']\n",
    "    created = datetime.datetime.fromtimestamp(subm['created_utc'])\n",
    "    numComms = subm['num_comments']\n",
    "    permalink = subm['permalink']\n",
    "    \n",
    "    subData.append((sub_id,title,url,author,score,created,numComms,permalink,flair))\n",
    "    subStats[sub_id] = subData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subreddit to query\n",
    "sub='guns'\n",
    "\n",
    "# Query time range\n",
    "before = \"1569888000\" #ends by 10/1/2016\n",
    "after = \"1451606400\"  #starts at 1/1/2016\n",
    "query = \"gun control\" #key word\n",
    "subCount = 0\n",
    "subStats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.pushshift.io/reddit/search/submission/?title=gun control&size=1000&after=1451606400&before=1569888000&subreddit=guns\n",
      "383\n",
      "2019-09-29 00:10:02\n",
      "https://api.pushshift.io/reddit/search/submission/?title=gun control&size=1000&after=1569741002&before=1569888000&subreddit=guns\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "data = getPushshiftData(query, after, before, sub)\n",
    "\n",
    "# Will gather data until the end date\n",
    "while len(data) > 0:\n",
    "    for submission in data:\n",
    "        collectSubData(submission)\n",
    "        subCount+=1\n",
    "        \n",
    "    # Calls getPushshiftData() with the created date of the last submission\n",
    "    print(len(data))\n",
    "    print(str(datetime.datetime.fromtimestamp(data[-1]['created_utc'])))\n",
    "    after = data[-1]['created_utc']\n",
    "    data = getPushshiftData(query, after, before, sub)\n",
    "    \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383 submissions have added to list\n",
      "1st entry is:\n",
      "Obama to impose new gun control curbs next week created: 2016-01-01 08:00:52\n",
      "Last entry is:\n",
      "Tennessee Man Faces Citation For His Fuck Gun Control Bumper Sticker created: 2019-09-29 00:10:02\n"
     ]
    }
   ],
   "source": [
    "# Print out result\n",
    "\n",
    "print(str(len(subStats)) + \" submissions have added to list\")\n",
    "print(\"1st entry is:\")\n",
    "print(list(subStats.values())[0][0][1] + \" created: \" + str(list(subStats.values())[0][0][5]))\n",
    "print(\"Last entry is:\")\n",
    "print(list(subStats.values())[-1][0][1] + \" created: \" + str(list(subStats.values())[-1][0][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input filename of submission file, please add .csv\n",
      "guns_2016_to_2019.csv\n",
      "383 submissions have been uploaded\n"
     ]
    }
   ],
   "source": [
    "# Export file to csv\n",
    "\n",
    "def updateSubs_file():\n",
    "    upload_count = 0\n",
    "    location = \"../data/reddit_\"\n",
    "    print(\"input filename of submission file, please add .csv\")\n",
    "    filename = input()\n",
    "    file = location + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as file: \n",
    "        a = csv.writer(file, delimiter=',')\n",
    "        headers = [\"Post ID\",\"Title\",\"Url\",\"Author\",\"Score\",\"Publish Date\",\"Total No. of Comments\",\"Permalink\",\"Flair\"]\n",
    "        a.writerow(headers)\n",
    "        for sub in subStats:\n",
    "            a.writerow(subStats[sub][0])\n",
    "            upload_count+=1\n",
    "            \n",
    "        print(str(upload_count) + \" submissions have been uploaded\")\n",
    "updateSubs_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
